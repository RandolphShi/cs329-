{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ontology and Taxonomy\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "* [Install WordNet](#Install-WordNet)\n",
    "* [Synsets](#Synsets)\n",
    "* [Lemmas](#Lemmas)\n",
    "\n",
    "## Reference\n",
    "\n",
    "* https://www.nltk.org/howto/wordnet.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install WordNet\n",
    "\n",
    "Verify the SSL (Secure Sockets Layer) certificate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install WordNet from [NLTK](https://www.nltk.org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/jdchoi/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synsets\n",
    "\n",
    "Retrieve all synsets of a word as the list of [Synset](https://www.nltk.org/api/nltk.corpus.reader.html?highlight=synset#nltk.corpus.reader.wordnet.Synset):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('dog.n.01'),\n",
       " Synset('frump.n.01'),\n",
       " Synset('dog.n.03'),\n",
       " Synset('cad.n.01'),\n",
       " Synset('frank.n.02'),\n",
       " Synset('pawl.n.01'),\n",
       " Synset('andiron.n.01'),\n",
       " Synset('chase.v.01')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "wn.synsets('dog')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can specify the part-of-speech (tag) of the word:\n",
    "\n",
    "* `n`: noun\n",
    "* `v`: verb\n",
    "* `a`: adjective\n",
    "* `r`: adverb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('dog.n.01'),\n",
       " Synset('frump.n.01'),\n",
       " Synset('dog.n.03'),\n",
       " Synset('cad.n.01'),\n",
       " Synset('frank.n.02'),\n",
       " Synset('pawl.n.01'),\n",
       " Synset('andiron.n.01')]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dogs = wn.synsets('dog', pos='n')\n",
    "dogs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve the synset directly from the sense ID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog_0 = wn.synset('dog.n.01')\n",
    "\n",
    "Synset == dogs[0]\n",
    "Synset == dogs[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve the direct hyponyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('basenji.n.01'),\n",
       " Synset('corgi.n.01'),\n",
       " Synset('cur.n.01'),\n",
       " Synset('dalmatian.n.02'),\n",
       " Synset('great_pyrenees.n.01'),\n",
       " Synset('griffon.n.02'),\n",
       " Synset('hunting_dog.n.01'),\n",
       " Synset('lapdog.n.01'),\n",
       " Synset('leonberg.n.01'),\n",
       " Synset('mexican_hairless.n.01'),\n",
       " Synset('newfoundland.n.01'),\n",
       " Synset('pooch.n.01'),\n",
       " Synset('poodle.n.01'),\n",
       " Synset('pug.n.01'),\n",
       " Synset('puppy.n.01'),\n",
       " Synset('spitz.n.01'),\n",
       " Synset('toy_dog.n.01'),\n",
       " Synset('working_dog.n.01')]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog_0.hyponyms()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retreive the direct hypernyms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('canine.n.02'), Synset('domestic_animal.n.01')]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog_0.hypernyms()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve all indrect hypernyms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Synset('entity.n.01'),\n",
       "  Synset('physical_entity.n.01'),\n",
       "  Synset('object.n.01'),\n",
       "  Synset('whole.n.02'),\n",
       "  Synset('living_thing.n.01'),\n",
       "  Synset('organism.n.01'),\n",
       "  Synset('animal.n.01'),\n",
       "  Synset('chordate.n.01'),\n",
       "  Synset('vertebrate.n.01'),\n",
       "  Synset('mammal.n.01'),\n",
       "  Synset('placental.n.01'),\n",
       "  Synset('carnivore.n.01'),\n",
       "  Synset('canine.n.02'),\n",
       "  Synset('dog.n.01')],\n",
       " [Synset('entity.n.01'),\n",
       "  Synset('physical_entity.n.01'),\n",
       "  Synset('object.n.01'),\n",
       "  Synset('whole.n.02'),\n",
       "  Synset('living_thing.n.01'),\n",
       "  Synset('organism.n.01'),\n",
       "  Synset('animal.n.01'),\n",
       "  Synset('domestic_animal.n.01'),\n",
       "  Synset('dog.n.01')]]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog_0.hypernym_paths()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmas\n",
    "\n",
    "Retrieve all [Lemmas](https://www.nltk.org/api/nltk.corpus.reader.html?highlight=lemma#nltk.corpus.reader.wordnet.Lemma) (synonyms) of the Synset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('dog.n.01.dog'),\n",
       " Lemma('dog.n.01.domestic_dog'),\n",
       " Lemma('dog.n.01.Canis_familiaris')]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog_0_lemmas = dog_0.lemmas()\n",
    "dog_0_lemmas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve only the names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog\n",
      "domestic_dog\n",
      "Canis_familiaris\n"
     ]
    }
   ],
   "source": [
    "for l in dog_0_lemmas:\n",
    "    print(l.name())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve the lemma directly from the sense ID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_0_lemma = wn.lemma('dog.n.01.dog')\n",
    "l = dog_0_lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve the frequency of the lemma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog 42\n",
      "domestic_dog 0\n",
      "Canis_familiaris 0\n"
     ]
    }
   ],
   "source": [
    "for l in dog_0.lemmas():\n",
    "    print(l.name(), l.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Write a function that takes a word and an optional POS tag, and returns the set of all synonyms of the word:\n",
    "\n",
    "```python\n",
    "def synonyms(word: str, pos: Optional[str]=None, count: Optional[int]=0) -> Set[str]:\n",
    "    # To be filled\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Set, Optional\n",
    "\n",
    "def synonyms(word: str, pos: Optional[str]=None, count: Optional[int]=0) -> Set[str]:\n",
    "    syns = set()\n",
    "\n",
    "    for synset in wn.synsets(word, pos):\n",
    "        for lemma in synset.lemmas():\n",
    "            if lemma.count() >= count:\n",
    "                syns.add(lemma.name())\n",
    "\n",
    "    return syns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Canis_familiaris',\n",
       " 'andiron',\n",
       " 'blackguard',\n",
       " 'bounder',\n",
       " 'cad',\n",
       " 'click',\n",
       " 'detent',\n",
       " 'dog',\n",
       " 'dog-iron',\n",
       " 'domestic_dog',\n",
       " 'firedog',\n",
       " 'frank',\n",
       " 'frankfurter',\n",
       " 'frump',\n",
       " 'heel',\n",
       " 'hot_dog',\n",
       " 'hotdog',\n",
       " 'hound',\n",
       " 'pawl',\n",
       " 'weenie',\n",
       " 'wiener',\n",
       " 'wienerwurst'}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synonyms('dog', 'n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dog', 'hound'}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synonyms('dog', 'n', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chase', 'dog', 'go_after', 'hound', 'track', 'trail'}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synonyms('dog', count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also rerieve antonyms of the lemma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buy [Lemma('sell.v.01.sell')]\n",
      "purchase []\n"
     ]
    }
   ],
   "source": [
    "buy = wn.synset('buy.v.01')\n",
    "for l in buy.lemmas():\n",
    "    print(l.name(), l.antonyms())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lowest Common Hypernyms\n",
    "\n",
    "NLTK already provides a method to find the lowest common hypernyms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('carnivore.n.01')]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog = wn.synset('dog.n.01')\n",
    "cat = wn.synset('cat.n.01')\n",
    "dog.lowest_common_hypernyms(cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK also provides methods to measure the similarty between two senses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2\n",
      "2.0281482472922856\n",
      "0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "print(dog.path_similarity(cat))\n",
    "print(dog.lch_similarity(cat))\n",
    "print(dog.wup_similarity(cat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Write a function that takes two sense IDs, finds the lowest common hypernyms, and returns the path from each lowest common hypernym to its root:\n",
    "\n",
    "```python\n",
    "def lch_paths(sense_0: str, sense_1: str) -> List[List[Synset]]:\n",
    "    # To be filled\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus.reader import Synset\n",
    "\n",
    "def lch_paths(sense_0: str, sense_1: str) -> List[List[Synset]]:\n",
    "    synset_0 = wn.synset(sense_0)\n",
    "    synset_1 = wn.synset(sense_1)\n",
    "    hypernym_paths_0 = synset_0.hypernym_paths()\n",
    "    lch = synset_0.lowest_common_hypernyms(synset_1)\n",
    "    paths = []\n",
    "\n",
    "    for hypernym in lch:\n",
    "        for syn_list in hypernym_paths_0:\n",
    "            i = next((i for i, syn in enumerate(syn_list) if syn == hypernym), -1)\n",
    "            if i >= 0: paths.append(syn_list[:i+1])\n",
    "\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entity.n.01 -> physical_entity.n.01 -> object.n.01 -> whole.n.02 -> living_thing.n.01 -> organism.n.01 -> animal.n.01 -> chordate.n.01 -> vertebrate.n.01 -> mammal.n.01 -> placental.n.01 -> carnivore.n.01\n"
     ]
    }
   ],
   "source": [
    "paths = lch_paths('dog.n.01', 'cat.n.01')\n",
    "for path in paths:\n",
    "    print(' -> '.join([syn.name() for syn in path]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
